import os

Import('env')
with open(env['PROJECT_TOOL_S']) as f:
    exec(f.read())

SRCS = Glob('src/*.c*')
INCLUDE = []
PRIVATE_INCLUDE = []
REQUIREMENTS = ['pthread']
STATIC_LIB = []
DYNAMIC_LIB = []
DEFINITIONS = []
DEFINITIONS_PRIVATE = []
LDFLAGS = []
LINK_SEARCH_PATH = []
STATIC_FILES = []

STATIC_FILES += [AFile('_tokenizer.py')]

env['COMPONENTS'].append({'target':'llm_tokenizer',
                          'SRCS':SRCS,
                          'INCLUDE':INCLUDE,
                          'PRIVATE_INCLUDE':PRIVATE_INCLUDE,
                          'REQUIREMENTS':REQUIREMENTS,
                          'STATIC_LIB':STATIC_LIB,
                          'DYNAMIC_LIB':DYNAMIC_LIB,
                          'DEFINITIONS':DEFINITIONS,
                          'DEFINITIONS_PRIVATE':DEFINITIONS_PRIVATE,
                          'LDFLAGS':LDFLAGS,
                          'LINK_SEARCH_PATH':LINK_SEARCH_PATH,
                          'STATIC_FILES':STATIC_FILES,
                          'REGISTER':'project'
                          })
